{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c154689",
   "metadata": {},
   "source": [
    "## Linear Model: Preprocessing Strategy ##\n",
    "\n",
    "* Define features (X) and target variable (y).\n",
    "\n",
    "* Split the dataset into train, test, validation sets (e.g., 70/20/10 split);\n",
    "\n",
    "**Linear Model Preprocessor 5 steps (python object)**\n",
    "\n",
    "*No imputation, no scaling, no capping, no encoding for price!!!*\n",
    "\n",
    "TRAIN SET:\n",
    "- Handle missing values: missingness is meaningful here; impute Nan with median and include a missing_flag indicator;\n",
    "- Handle skeweness:log-transform skewed features and target, cap outliers at 1-99%;\n",
    "- Encoding categorical variables (TargetEncoding and OneHotEncoder), and scaling (StandardScaling);\n",
    "\n",
    "TEST, VALIDATION SETS:\n",
    "Apply the same sub-steps from above but with the parameters learned from the **training set**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1b1039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>subproperty_type</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>locality</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>fl_garden</th>\n",
       "      <th>garden_sqm</th>\n",
       "      <th>fl_swimming_pool</th>\n",
       "      <th>fl_floodzone</th>\n",
       "      <th>state_building</th>\n",
       "      <th>primary_energy_consumption_sqm</th>\n",
       "      <th>epc</th>\n",
       "      <th>heating_type</th>\n",
       "      <th>fl_double_glazing</th>\n",
       "      <th>cadastral_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34221000</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>2050</td>\n",
       "      <td>51.217172</td>\n",
       "      <td>4.379982</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>231.0</td>\n",
       "      <td>poor</td>\n",
       "      <td>GAS</td>\n",
       "      <td>1</td>\n",
       "      <td>922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2104000</td>\n",
       "      <td>449000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>East Flanders</td>\n",
       "      <td>Gent</td>\n",
       "      <td>9185</td>\n",
       "      <td>51.174944</td>\n",
       "      <td>3.845248</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>221.0</td>\n",
       "      <td>poor</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>1</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34036000</td>\n",
       "      <td>335000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Brussels-Capital</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1070</td>\n",
       "      <td>50.842043</td>\n",
       "      <td>4.334543</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58496000</td>\n",
       "      <td>501000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Turnhout</td>\n",
       "      <td>2275</td>\n",
       "      <td>51.238312</td>\n",
       "      <td>4.817192</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>99.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48727000</td>\n",
       "      <td>982700.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>DUPLEX</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>Walloon Brabant</td>\n",
       "      <td>Nivelles</td>\n",
       "      <td>1410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75503</th>\n",
       "      <td>30785000</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>Wallonia</td>\n",
       "      <td>Hainaut</td>\n",
       "      <td>Tournai</td>\n",
       "      <td>7640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75504</th>\n",
       "      <td>13524000</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>PENTHOUSE</td>\n",
       "      <td>Brussels-Capital</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1200</td>\n",
       "      <td>50.840183</td>\n",
       "      <td>4.435570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>95.0</td>\n",
       "      <td>good</td>\n",
       "      <td>GAS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75505</th>\n",
       "      <td>43812000</td>\n",
       "      <td>798000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>MIXED_USE_BUILDING</td>\n",
       "      <td>Brussels-Capital</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TO_RENOVATE</td>\n",
       "      <td>351.0</td>\n",
       "      <td>bad</td>\n",
       "      <td>GAS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75506</th>\n",
       "      <td>49707000</td>\n",
       "      <td>575000.0</td>\n",
       "      <td>HOUSE</td>\n",
       "      <td>VILLA</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>West Flanders</td>\n",
       "      <td>Veurne</td>\n",
       "      <td>8670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AS_NEW</td>\n",
       "      <td>269.0</td>\n",
       "      <td>poor</td>\n",
       "      <td>GAS</td>\n",
       "      <td>1</td>\n",
       "      <td>795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75507</th>\n",
       "      <td>65278000</td>\n",
       "      <td>515000.0</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>PENTHOUSE</td>\n",
       "      <td>Flanders</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>Antwerp</td>\n",
       "      <td>2000</td>\n",
       "      <td>51.220753</td>\n",
       "      <td>4.410247</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75508 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     price property_type    subproperty_type            region  \\\n",
       "0      34221000  225000.0     APARTMENT           APARTMENT          Flanders   \n",
       "1       2104000  449000.0         HOUSE               HOUSE          Flanders   \n",
       "2      34036000  335000.0     APARTMENT           APARTMENT  Brussels-Capital   \n",
       "3      58496000  501000.0         HOUSE               HOUSE          Flanders   \n",
       "4      48727000  982700.0     APARTMENT              DUPLEX          Wallonia   \n",
       "...         ...       ...           ...                 ...               ...   \n",
       "75503  30785000  210000.0     APARTMENT           APARTMENT          Wallonia   \n",
       "75504  13524000  780000.0     APARTMENT           PENTHOUSE  Brussels-Capital   \n",
       "75505  43812000  798000.0         HOUSE  MIXED_USE_BUILDING  Brussels-Capital   \n",
       "75506  49707000  575000.0         HOUSE               VILLA          Flanders   \n",
       "75507  65278000  515000.0     APARTMENT           PENTHOUSE          Flanders   \n",
       "\n",
       "              province  locality  zip_code   latitude  longitude  ...  \\\n",
       "0              Antwerp   Antwerp      2050  51.217172   4.379982  ...   \n",
       "1        East Flanders      Gent      9185  51.174944   3.845248  ...   \n",
       "2             Brussels  Brussels      1070  50.842043   4.334543  ...   \n",
       "3              Antwerp  Turnhout      2275  51.238312   4.817192  ...   \n",
       "4      Walloon Brabant  Nivelles      1410        NaN        NaN  ...   \n",
       "...                ...       ...       ...        ...        ...  ...   \n",
       "75503          Hainaut   Tournai      7640        NaN        NaN  ...   \n",
       "75504         Brussels  Brussels      1200  50.840183   4.435570  ...   \n",
       "75505         Brussels  Brussels      1080        NaN        NaN  ...   \n",
       "75506    West Flanders    Veurne      8670        NaN        NaN  ...   \n",
       "75507          Antwerp   Antwerp      2000  51.220753   4.410247  ...   \n",
       "\n",
       "       fl_garden  garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
       "0              0         0.0                 0             0         MISSING   \n",
       "1              0         0.0                 0             0         MISSING   \n",
       "2              0         0.0                 0             1          AS_NEW   \n",
       "3              0         0.0                 0             1         MISSING   \n",
       "4              1       142.0                 0             0          AS_NEW   \n",
       "...          ...         ...               ...           ...             ...   \n",
       "75503          0         0.0                 0             1          AS_NEW   \n",
       "75504          0         0.0                 0             0          AS_NEW   \n",
       "75505          0         0.0                 0             1     TO_RENOVATE   \n",
       "75506          1         NaN                 0             1          AS_NEW   \n",
       "75507          0         0.0                 0             0         MISSING   \n",
       "\n",
       "      primary_energy_consumption_sqm        epc  heating_type  \\\n",
       "0                              231.0       poor           GAS   \n",
       "1                              221.0       poor       MISSING   \n",
       "2                                NaN    MISSING           GAS   \n",
       "3                               99.0  excellent       MISSING   \n",
       "4                               19.0  excellent           GAS   \n",
       "...                              ...        ...           ...   \n",
       "75503                            NaN    MISSING       MISSING   \n",
       "75504                           95.0       good           GAS   \n",
       "75505                          351.0        bad           GAS   \n",
       "75506                          269.0       poor           GAS   \n",
       "75507                            NaN    MISSING       MISSING   \n",
       "\n",
       "       fl_double_glazing  cadastral_income  \n",
       "0                      1             922.0  \n",
       "1                      1             406.0  \n",
       "2                      0               NaN  \n",
       "3                      0               NaN  \n",
       "4                      0               NaN  \n",
       "...                  ...               ...  \n",
       "75503                  1               NaN  \n",
       "75504                  1               NaN  \n",
       "75505                  0               NaN  \n",
       "75506                  1             795.0  \n",
       "75507                  1               NaN  \n",
       "\n",
       "[75508 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"cleaned_properties.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce95c168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define features (X) and target variable (y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns = [\"price\",\"id\",\"zip_code\",\"latitude\",\"longitude\"])\n",
    "y = df[\"price\"]\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52667e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into train, test, validation sets (e.g., 60/20/20 split);\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X,y, test_size=0.2, random_state = 86)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp,y_temp, test_size = 0.25, random_state = 86)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830a5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(X_val))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d388159",
   "metadata": {},
   "source": [
    "## Linear Model Preprocessor 5 steps ##\n",
    "impute → cap → log → scale → encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950af444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,FunctionTransformer, StandardScaler,OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764eefc0",
   "metadata": {},
   "source": [
    "Following the multicolinearity analysis, there are certain features candidates for dropping. Need to choose one among the identified groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afe70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAN: replace NAN with median and add a missing_fl column here:\n",
    "numeric_features = [\"cadastral_income\", \"surface_land_sqm\", \"construction_year\",\n",
    "                    \"primary_energy_consumption_sqm\",\"nbr_bedrooms\",\"nbr_frontages\",\n",
    "                    \"terrace_sqm\", \"total_area_sqm\",\"garden_sqm\"]\n",
    "\n",
    "skewed_features = [\"surface_land_sqm\",\"total_area_sqm\", \"garden_sqm\",\"terrace_sqm\"]\n",
    "\n",
    "# No NAN to be handled, only encoding\n",
    "categorical_onehot = [\"property_type\",\"region\",\"province\",\"heating_type\",\"equipped_kitchen\", \"epc\"]\n",
    "categorical_target = [\"subproperty_type\",\"locality\",\"state_building\"]\n",
    "\n",
    "# # No NAN to be handled and no encoding\n",
    "binary_features = [\"fl_floodzone\", \"fl_double_glazing\", \"fl_open_fire\",\"fl_terrace\", \n",
    "                        \"fl_garden\", \"fl_swimming_pool\", \"fl_furnished\"\n",
    "                        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84df359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for log-transformation\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "# Class Outlier Capper\n",
    "class OutlierCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Compute thresholds for each column based on training data\n",
    "        self.lower_ = np.quantile(X, self.lower_quantile, axis=0)\n",
    "        self.upper_ = np.quantile(X, self.upper_quantile, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Clip values to the learned thresholds\n",
    "        return np.clip(X, self.lower_, self.upper_)\n",
    "    \n",
    "capper = OutlierCapper(lower_quantile=0.05, upper_quantile=0.95)\n",
    "\n",
    "# Pipeline for numeric columns (imputation, scale, capping (capping needs to come as a parameter from train data - leakage issue))\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('cap',capper),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for numeric features that need log-transform (specific order for cap,log,scaler)\n",
    "log_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('cap', capper),\n",
    "    ('log', log_transformer),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for one-hot categorical features - binary features are included because \"MISSING\" is treated as a category\n",
    "onehot_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline for label/ordinal categorical features - \"MISSING\" is treated as a category\n",
    "target_pipeline = Pipeline([\n",
    "    ('target_enc', TargetEncoder(smoothing=1.0))\n",
    "])\n",
    "\n",
    "# Putting all pipelines together; TargetEncoder is SUPERVISED (it needs y_train)\n",
    "\n",
    "preprocessor_linear = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, [f for f in numeric_features if f not in skewed_features]),\n",
    "    ('log', log_pipeline, skewed_features),\n",
    "    ('onehot', onehot_pipeline, categorical_onehot),\n",
    "    ('label', target_pipeline, categorical_target),\n",
    "    ('binary', 'passthrough', binary_features) # Just passing them as-is\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b18cff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_processed shape: (45304, 67)\n",
      "X_test_processed shape: (15102, 67)\n",
      "First 5 rows of processed X_train:\n",
      "[[-1.7221717   1.18843323 -0.14593329  0.27205378 -1.27501337]\n",
      " [-0.12257671  1.26611278 -0.14593329 -1.53171094 -1.27501337]\n",
      " [-0.69457326  0.13975939 -0.86666715 -0.62982858  0.18560831]\n",
      " [-0.12257671  1.26611278 -0.14593329 -0.62982858  0.18560831]\n",
      " [-0.12257671  0.13975939 -0.14593329  0.27205378  0.18560831]]\n",
      "First 5 rows of processed X_test:\n",
      "[[-1.51931246  0.13975939  0.67976182  0.27205378 -1.27501337]\n",
      " [-0.12257671 -1.29731216 -0.41883252  1.17393613 -1.27501337]\n",
      " [-0.27222697  0.99423437 -1.11157672 -0.62982858 -1.27501337]\n",
      " [-0.12257671  1.26611278 -0.14593329  0.27205378  0.18560831]\n",
      " [ 0.23658391 -1.06427353  1.41449051  0.27205378 -1.27501337]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Fit on training data\n",
    "X_train_processed = preprocessor_linear.fit_transform(X_train, y_train) #HERE ADDING y_train because of TargetEncoder (supervised encoder), safely handled by ColumnTransformer\n",
    "\n",
    "# Transform test data (re-use fitted transformers)\n",
    "X_test_processed = preprocessor_linear.transform(X_test)\n",
    "\n",
    "print(\"X_train_processed shape:\", X_train_processed.shape)\n",
    "print(\"X_test_processed shape:\", X_test_processed.shape)\n",
    "\n",
    "# For X_train\n",
    "print(\"First 5 rows of processed X_train:\")\n",
    "print(X_train_processed[:5, :5])  # first 5 rows and first 5 columns\n",
    "\n",
    "# For X_test\n",
    "print(\"First 5 rows of processed X_test:\")\n",
    "print(X_test_processed[:5, :5])\n",
    "\n",
    "print(type(X_train_processed))\n",
    "print(type(X_test_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f13ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(column_names) = 67\n",
      "X_train_processed.shape[1] = 67\n",
      "['cadastral_income', 'construction_year', 'primary_energy_consumption_sqm', 'nbr_bedrooms', 'nbr_frontages', 'cadastral_income_missing_flag', 'construction_year_missing_flag', 'primary_energy_consumption_sqm_missing_flag', 'nbr_frontages_missing_flag', 'surface_land_sqm', 'total_area_sqm', 'garden_sqm', 'terrace_sqm', 'surface_land_sqm_missing_flag', 'total_area_sqm_missing_flag', 'garden_sqm_missing_flag', 'terrace_sqm_missing_flag', 'property_type_APARTMENT', 'property_type_HOUSE', 'region_Brussels-Capital', 'region_Flanders', 'region_Wallonia', 'region_missing', 'province_Antwerp', 'province_Brussels', 'province_East Flanders', 'province_Flemish Brabant', 'province_Hainaut', 'province_Limburg', 'province_Liège', 'province_Luxembourg', 'province_Namur', 'province_Walloon Brabant', 'province_West Flanders', 'province_missing', 'heating_type_CARBON', 'heating_type_ELECTRIC', 'heating_type_FUELOIL', 'heating_type_GAS', 'heating_type_MISSING', 'heating_type_PELLET', 'heating_type_SOLAR', 'heating_type_WOOD', 'equipped_kitchen_HYPER_EQUIPPED', 'equipped_kitchen_INSTALLED', 'equipped_kitchen_MISSING', 'equipped_kitchen_NOT_INSTALLED', 'equipped_kitchen_SEMI_EQUIPPED', 'equipped_kitchen_USA_HYPER_EQUIPPED', 'equipped_kitchen_USA_INSTALLED', 'equipped_kitchen_USA_SEMI_EQUIPPED', 'equipped_kitchen_USA_UNINSTALLED', 'epc_MISSING', 'epc_bad', 'epc_excellent', 'epc_good', 'epc_poor', 'subproperty_type', 'locality', 'state_building', 'fl_floodzone', 'fl_double_glazing', 'fl_open_fire', 'fl_terrace', 'fl_garden', 'fl_swimming_pool', 'fl_furnished']\n"
     ]
    }
   ],
   "source": [
    "# Get the features' names back and convert ColumnTransformer arrays into df \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def get_column_names(ct):\n",
    "    \"\"\"\n",
    "    Return list of output column names produced by a fitted ColumnTransformer `ct`.\n",
    "    Handles Pipelines, SimpleImputer(add_indicator=True) inside pipelines,\n",
    "    and transformers that implement get_feature_names_out.\n",
    "    \"\"\"\n",
    "    feature_names = []\n",
    "\n",
    "    for name, transformer, cols in ct.transformers_:\n",
    "        # Skip dropped transformers\n",
    "        if transformer == 'drop':\n",
    "            continue\n",
    "\n",
    "        # passthrough: keep original names\n",
    "        if transformer == 'passthrough':\n",
    "            feature_names.extend(list(cols))\n",
    "            continue\n",
    "\n",
    "        # Some ColumnTransformer entries may be (name, transformer, slice) where\n",
    "        # transformer is a Pipeline or transformer instance.\n",
    "        # We'll treat Pipeline specially.\n",
    "        if isinstance(transformer, Pipeline):\n",
    "            \n",
    "            last_step = transformer.steps[-1][1]\n",
    "            if hasattr(last_step, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    names = last_step.get_feature_names_out(cols)\n",
    "                    feature_names.extend(list(names))\n",
    "                    continue\n",
    "                except Exception:\n",
    "                    # if it fails for any reason, fall through to other checks\n",
    "                    pass\n",
    "\n",
    "            imputer_with_indicator = None\n",
    "            for step_name, step_obj in transformer.steps:\n",
    "                if isinstance(step_obj, SimpleImputer) and getattr(step_obj, \"add_indicator\", False):\n",
    "                    imputer_with_indicator = step_obj\n",
    "                    break\n",
    "\n",
    "            if imputer_with_indicator is not None:\n",
    "                # Imputer keeps original number of columns + indicator cols (one per input col with NaNs seen during fit)\n",
    "                feature_names.extend(list(cols))\n",
    "                if hasattr(imputer_with_indicator, 'indicator_'):\n",
    "                    indicator_names = [f\"{cols[i]}_missing_flag\" for i in imputer_with_indicator.indicator_.features_]\n",
    "                    feature_names.extend(indicator_names)\n",
    "                continue\n",
    "\n",
    "            feature_names.extend(list(cols))\n",
    "            continue\n",
    "\n",
    "        # If transformer is not a Pipeline\n",
    "        # Try to use get_feature_names_out if present\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            try:\n",
    "                names = transformer.get_feature_names_out(cols)\n",
    "                feature_names.extend(list(names))\n",
    "                continue\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Check if this transformer itself is a SimpleImputer with add_indicator=True\n",
    "        if isinstance(transformer, SimpleImputer) and getattr(transformer, \"add_indicator\", False):\n",
    "            feature_names.extend(list(cols))\n",
    "            if hasattr(transformer, 'indicator_'): # Thie priece resolves the issue when missing_fl colummn is created but not needed, causing issue when converting to df\n",
    "                indicator_names = [f\"{cols[i]}_missing_flag\" for i in transformer.indicator_.features_]\n",
    "                feature_names.extend(indicator_names)\n",
    "            continue\n",
    "\n",
    "        # final fallback: original column names\n",
    "        feature_names.extend(list(cols))\n",
    "\n",
    "    return feature_names\n",
    "\n",
    "column_names = get_column_names(preprocessor_linear)\n",
    "\n",
    "print(\"len(column_names) =\", len(column_names))\n",
    "print(\"X_train_processed.shape[1] =\", X_train_processed.shape[1])\n",
    "print(column_names)\n",
    "\n",
    "# If they match, convert to DataFrame\n",
    "if len(column_names) == X_train_processed.shape[1]:\n",
    "    X_train_processed_df = pd.DataFrame(X_train_processed, columns=column_names)\n",
    "    X_test_processed_df  = pd.DataFrame(X_test_processed,  columns=column_names)\n",
    "else:\n",
    "    raise ValueError(f\"Column count mismatch: names={len(column_names)} vs array columns={X_train_processed.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9485a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer blocks and cols:\n",
      "BLOCK: num cols: ['cadastral_income', 'construction_year', 'primary_energy_consumption_sqm', 'nbr_bedrooms', 'nbr_frontages']\n",
      "  is pipeline: True\n",
      "  pipeline steps: dict_keys(['imputer', 'cap', 'scaler'])\n",
      "    step: imputer <class 'sklearn.impute._base.SimpleImputer'> True True\n",
      "    step: cap <class '__main__.OutlierCapper'> False False\n",
      "    step: scaler <class 'sklearn.preprocessing._data.StandardScaler'> False True\n",
      "BLOCK: log cols: ['surface_land_sqm', 'total_area_sqm', 'garden_sqm', 'terrace_sqm']\n",
      "  is pipeline: True\n",
      "  pipeline steps: dict_keys(['imputer', 'cap', 'log', 'scaler'])\n",
      "    step: imputer <class 'sklearn.impute._base.SimpleImputer'> True True\n",
      "    step: cap <class '__main__.OutlierCapper'> False False\n",
      "    step: log <class 'sklearn.preprocessing._function_transformer.FunctionTransformer'> False False\n",
      "    step: scaler <class 'sklearn.preprocessing._data.StandardScaler'> False True\n",
      "BLOCK: onehot cols: ['property_type', 'region', 'province', 'heating_type', 'equipped_kitchen', 'epc']\n",
      "  is pipeline: True\n",
      "  pipeline steps: dict_keys(['imputer', 'encoder'])\n",
      "    step: imputer <class 'sklearn.impute._base.SimpleImputer'> False True\n",
      "    step: encoder <class 'sklearn.preprocessing._encoders.OneHotEncoder'> False True\n",
      "BLOCK: label cols: ['subproperty_type', 'locality', 'state_building']\n",
      "  is pipeline: True\n",
      "  pipeline steps: dict_keys(['target_enc'])\n",
      "    step: target_enc <class 'category_encoders.target_encoder.TargetEncoder'> False True\n",
      "BLOCK: binary cols: ['fl_floodzone', 'fl_double_glazing', 'fl_open_fire', 'fl_terrace', 'fl_garden', 'fl_swimming_pool', 'fl_furnished']\n",
      "  is pipeline: False\n",
      "  transformer type: <class 'sklearn.preprocessing._function_transformer.FunctionTransformer'> True\n",
      "OneHotEncoder output cols: 40\n"
     ]
    }
   ],
   "source": [
    "# Testing the output per pipeline block and whether the number of columns match the names\n",
    "column_names = get_column_names(preprocessor_linear)\n",
    "print(\"Transformer blocks and cols:\")\n",
    "for name, transformer, cols in preprocessor_linear.transformers_:\n",
    "    print(\"BLOCK:\", name, \"cols:\", cols)\n",
    "    print(\"  is pipeline:\", isinstance(transformer, Pipeline))\n",
    "    if isinstance(transformer, Pipeline):\n",
    "        print(\"  pipeline steps:\", transformer.named_steps.keys())\n",
    "        for step_name, step in transformer.steps:\n",
    "            print(\"    step:\", step_name, type(step), getattr(step, \"add_indicator\", False), hasattr(step, \"get_feature_names_out\"))\n",
    "    else:\n",
    "        print(\"  transformer type:\", type(transformer), hasattr(transformer, \"get_feature_names_out\"))\n",
    "\n",
    "\n",
    "onehot_cols = preprocessor_linear.named_transformers_['onehot'].named_steps['encoder'].get_feature_names_out(categorical_onehot)\n",
    "print(\"OneHotEncoder output cols:\", len(onehot_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16c1b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d187d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_swimming_pool\n",
       "0    4.112319e+05\n",
       "1    1.040320e+06\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (in)sanity check\n",
    "\n",
    "X_train['fl_swimming_pool'].value_counts()\n",
    "y_train.groupby(X_train['fl_swimming_pool']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4869739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform PRICE\n",
    " \n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log  = np.log1p(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337a532",
   "metadata": {},
   "source": [
    "## Training and Testing the Linear Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9405203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                feature  coefficient\n",
      "10                       total_area_sqm     0.231797\n",
      "65                     fl_swimming_pool     0.220506\n",
      "35                  heating_type_CARBON    -0.141772\n",
      "63                           fl_terrace    -0.137180\n",
      "48  equipped_kitchen_USA_HYPER_EQUIPPED     0.126990\n",
      "27                     province_Hainaut    -0.106291\n",
      "46       equipped_kitchen_NOT_INSTALLED    -0.105935\n",
      "12                          terrace_sqm     0.093480\n",
      "21                      region_Wallonia    -0.092023\n",
      "43      equipped_kitchen_HYPER_EQUIPPED     0.090743\n",
      "47       equipped_kitchen_SEMI_EQUIPPED    -0.088347\n",
      "53                              epc_bad    -0.084062\n",
      "3                          nbr_bedrooms     0.083469\n",
      "0                      cadastral_income     0.078632\n",
      "54                        epc_excellent     0.077334\n",
      "56                             epc_poor    -0.076411\n",
      "41                   heating_type_SOLAR     0.069558\n",
      "42                    heating_type_WOOD    -0.064517\n",
      "66                         fl_furnished     0.063888\n",
      "28                     province_Limburg    -0.063178\n",
      "36                heating_type_ELECTRIC     0.053160\n",
      "5         cadastral_income_missing_flag     0.051953\n",
      "33               province_West Flanders     0.049723\n",
      "62                         fl_open_fire     0.049307\n",
      "2        primary_energy_consumption_sqm    -0.048505\n"
     ]
    }
   ],
   "source": [
    "# Training the Linear model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_processed_df, y_train_log)\n",
    "\n",
    "# Coefficients with feature names\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X_train_processed_df.columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values(by='coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coef_df.head(25))  # top 10 strongest features\n",
    "\n",
    "# Example interpretation below: increasing total area by 1 std oncreased log(price) by 0.23, corresponding\n",
    "# to around 26% increase in price.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f45dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NECESSARY\n",
    "# Checking significance (not possible with sklearn)\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "#X = X_train_processed_df\n",
    "#y = y_train_log\n",
    "\n",
    "# Add intercept term\n",
    "#X_sm = sm.add_constant(X)\n",
    "\n",
    "#ols_model = sm.OLS(y, X_sm).fit()\n",
    "#print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd33abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       actual train  predicted train\n",
      "19103      470453.0    304466.425110\n",
      "59696      215000.0    206506.618299\n",
      "73754      229000.0    254941.871304\n",
      "12840      324138.0    277699.333738\n",
      "11058      499000.0    477718.971121\n",
      "       actual test  predicted test\n",
      "40080     155000.0   144239.230691\n",
      "43868     585000.0   469521.124976\n",
      "56179     201000.0   202858.685318\n",
      "48114     595398.0   591107.418504\n",
      "3304      295000.0   309561.631443\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "y_train_pred_log = model.predict(X_train_processed_df) # First level check for underfitting (training error too high)\n",
    "y_test_pred_log = model.predict(X_test_processed_df) # Prediction on the unseen data\n",
    "y_test_pred = np.expm1(y_test_pred_log) \n",
    "y_train_pred = np.expm1(y_train_pred_log)\n",
    "\n",
    "train_results = pd.DataFrame({\n",
    "    \"actual train\": y_train,\n",
    "    \"predicted train\": np.expm1(model.predict(X_train_processed_df))\n",
    "})\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    \"actual test\": y_test,\n",
    "    \"predicted test\": np.expm1(model.predict(X_test_processed_df))\n",
    "})\n",
    "\n",
    "print(train_results.head())\n",
    "print(test_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b8541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back-transform coefficients for interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85252393",
   "metadata": {},
   "source": [
    "## Metrics regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea82df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (original scale): 0.33954826665613613\n",
      "RMSE: 143477781261.8997\n",
      "R2 (log scale): 0.4645265851207946\n",
      "RMSE (log scale): 0.3419016547868019\n"
     ]
    }
   ],
   "source": [
    "# Adjusted R-sqr, RMSE\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "r2_log = r2_score(y_test_pred_log, np.log1p(y_test))\n",
    "mse_log = mean_squared_error(np.log1p(y_test), y_test_pred_log)\n",
    "\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "rmse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R2 (original scale):\", r2)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 (log scale):\", r2_log)\n",
    "print(\"RMSE (log scale):\", np.sqrt(mse_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed04cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: {'MAE': 122895.95500355208, 'RMSE': np.float64(332277.1726435241), 'R2': 0.40316051400669195}\n",
      "TEST:  {'MAE': 124093.27323195233, 'RMSE': np.float64(378784.6106455484), 'R2': 0.33954826665613613}\n"
     ]
    }
   ],
   "source": [
    "# Over/under-fitting test\n",
    "# train < test - overfitting (model memorizes training data)\n",
    "# train > test - underfitting (model is too simple or wrong features)\n",
    "#\n",
    "\n",
    "def evaluate(y_true, y_pred): # temporarily defining here, not globally\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "train_metrics = evaluate(y_train, y_train_pred)\n",
    "test_metrics  = evaluate(y_test,  y_test_pred)\n",
    "\n",
    "print(\"TRAIN:\", train_metrics)\n",
    "print(\"TEST: \", test_metrics)\n",
    "\n",
    "# Result interpretation: NO over/under-fitting  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5fcf3",
   "metadata": {},
   "source": [
    "## Full Pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_linear),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = full_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1828305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
